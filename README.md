# Muir College Solar Dashboard

Automated solar generation monitoring dashboard powered by GitHub Actions. Data is scraped daily from the Genergy portal and displayed on a live dashboard.

## ğŸŒŸ Features

- âœ… **Automated Data Collection** - Runs daily via GitHub Actions after sunset
- âœ… **Real-time Dashboard** - Live generation statistics and environmental impact
- âœ… **Incremental Processing** - Only processes new data since last run
- âœ… **7-Day History** - Tracks daily generation for the past week
- âœ… **Environmental Impact** - COâ‚‚ avoided, trees planted, households powered, etc.
- âœ… **GitHub Pages Hosting** - Free, fast, and reliable

## ğŸ“‹ Setup Instructions

### Step 1: Create GitHub Repository

1. Go to https://github.com/new
2. Repository name: `MuirCollege`
3. Description: "Muir College Solar Generation Dashboard"
4. Set to **Public**
5. âœ… Check "Add a README file"
6. Click **Create repository**

### Step 2: Enable GitHub Pages

1. Go to **Settings** â†’ **Pages**
2. Source: **Deploy from a branch**
3. Branch: **main** / **root**
4. Click **Save**
5. Wait 2-3 minutes for deployment

### Step 3: Add GitHub Secrets

Go to **Settings** â†’ **Secrets and variables** â†’ **Actions** â†’ **New repository secret**

Add these 2 secrets:

| Secret Name | Value | Description |
|-------------|-------|-------------|
| `SOLAR_EMAIL` | your_email@domain.com | Genergy portal login email |
| `SOLAR_PASSWORD` | your_password | Genergy portal password |

### Step 4: Upload Files

Upload all files from this folder to your GitHub repository:

```
.github/workflows/solar-data-update.yml
config.json
scraper.py
process_data.py
index.html
.gitignore
data/.gitkeep
data/daily/.gitkeep
README.md
```

**Method 1: Via GitHub Web Interface**
1. Click **Add file** â†’ **Upload files**
2. Drag and drop all files
3. Click **Commit changes**

**Method 2: Via Git Command Line**
```bash
git clone https://github.com/GenergyDashboard/MuirCollege.git
cd MuirCollege
# Copy all files into this directory
git add .
git commit -m "Initial setup"
git push
```

### Step 5: Update config.json

Edit `config.json` and update:
- `installed_capacity_kwp` - Your system size in kWp
- `initial_values.lifetime_total_kwh` - Current lifetime total from your system
- `initial_values.month_start_total_kwh` - Total kWh at start of current month

### Step 6: Run First Workflow

1. Go to **Actions** tab
2. Click on "Update Solar Data" workflow
3. Click **Run workflow** dropdown
4. Click **Run workflow** button (green)
5. Wait 2-3 minutes for it to complete
6. Check for green âœ… checkmark

### Step 7: View Your Dashboard

Go to: `https://GenergyDashboard.github.io/MuirCollege/`

You should see:
- âœ… Current power generation
- âœ… Today/Month/Lifetime totals
- âœ… Environmental impact statistics

## ğŸ“… Automated Schedule

The workflow runs automatically **3 times daily**:
- **10:00 AM SAST** (08:00 UTC)
- **3:00 PM SAST** (13:00 UTC)
- **8:00 PM SAST** (18:00 UTC)

You can also run it manually anytime from the Actions tab.

## ğŸ—‚ï¸ File Structure

```
MuirCollege/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ solar-data-update.yml    # GitHub Actions workflow
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ solar_data.json              # Main data file (generated)
â”‚   â”œâ”€â”€ persistent_totals.json       # Lifetime/monthly totals
â”‚   â”œâ”€â”€ latest_csv_timestamp.json    # Last processed timestamp
â”‚   â”œâ”€â”€ solar_export_latest.csv      # Latest CSV from scraper
â”‚   â”œâ”€â”€ last_scrape.json             # Scraper status
â”‚   â””â”€â”€ daily/                       # Daily CSV archives
â”œâ”€â”€ config.json                      # System configuration
â”œâ”€â”€ scraper.py                       # Playwright web scraper
â”œâ”€â”€ process_data.py                  # Data processor
â”œâ”€â”€ index.html                       # Public dashboard
â”œâ”€â”€ .gitignore                       # Git ignore rules
â””â”€â”€ README.md                        # This file
```

## ğŸ” How It Works

### 1. **Scraper (scraper.py)**
- Launches headless Chromium browser
- Logs into Genergy portal with credentials from secrets
- Searches for "Muir" site
- Opens insights page
- Sets data interval to 5 minutes
- Downloads CSV file
- Saves to `data/solar_export_latest.csv`

### 2. **Processor (process_data.py)**
- Reads CSV file
- Parses timestamps and power values
- **Incremental processing**: Only processes NEW rows since last run
- Handles day/month transitions
- Calculates environmental impact
- Saves multiple JSON files for dashboard

### 3. **Dashboard (index.html)**
- Loads `solar_data.json`
- Displays generation statistics
- Shows environmental impact
- Yesterday's data in separate section
- Historical day selector (past 7 days)
- Auto-refreshes every minute

### 4. **Persistent Storage**
- `persistent_totals.json` - Lifetime and monthly totals
- `latest_csv_timestamp.json` - Last processed timestamp
- Prevents duplicate data processing
- Accumulates daily totals correctly

## ğŸ”§ Troubleshooting

### Workflow Fails on First Run
- This is normal! Playwright needs to install browser dependencies
- Just run it again - it will succeed

### "No data in CSV" Error
- Check that credentials are correct
- Verify the "Muir" search finds your site
- Check CSV is being downloaded

### Dashboard Shows "Unable to load solar data"
- Wait a few minutes after first workflow run
- Check that `data/dashboard_data.json` was created
- Verify GitHub Pages is enabled

### Data Not Updating
- Check Actions tab for workflow errors
- Verify workflow ran successfully (green checkmark)
- Check that JSON files in data/ folder are updated

## ğŸ“Š Data Flow

```
GitHub Actions (3x daily: 8:00, 13:00, 18:00 UTC)
    â†“
scraper.py (Playwright automation)
    â†“
Download CSV â†’ data/solar_export_latest.csv
    â†“
process_data.py (Parse & calculate)
    â†“
Generate solar_data.json (single output file)
    â†“
Commit & Push to GitHub
    â†“
GitHub Pages Auto-deploys
    â†“
Dashboard updates (index.html)
```

## ğŸ” Security

- âœ… Credentials stored in GitHub Secrets (encrypted)
- âœ… Never exposed in logs or code
- âœ… Client login credentials separate from scraper credentials
- âœ… CSV downloads and screenshots ignored by git

## ğŸ“ Maintenance

### Update System Configuration
Edit `config.json` and commit changes

### Change Client Credentials
Update GitHub Secrets: `CLIENT_USERNAME` and `CLIENT_PASSWORD`

### View Workflow Logs
Actions tab â†’ Click on workflow run â†’ Click on job step

### Manual Run
Actions tab â†’ Update Solar Data â†’ Run workflow

## ğŸ¨ Customization

### Change Dashboard Branding
Edit `index.html`:
- Update title
- Change color scheme (CSS variables)
- Modify environmental impact cards

### Adjust Schedule
Edit `.github/workflows/solar-data-update.yml`:
```yaml
schedule:
  # 10:00 AM SAST = 08:00 UTC
  - cron: '0 8 * * *'
  # 3:00 PM SAST = 13:00 UTC
  - cron: '0 13 * * *'
  # 8:00 PM SAST = 18:00 UTC
  - cron: '0 18 * * *'
```

### Modify Environmental Factors
Edit `config.json` â†’ `environmental_factors` section

## ğŸ“ˆ What's Tracked

- **Current Power** - Latest power reading in watts
- **Daily Total** - Accumulated generation today (resets at midnight)
- **Monthly Total** - Accumulated generation this month
- **Lifetime Total** - All-time generation
- **7-Day History** - Past week's daily totals
- **Environmental Impact**:
  - COâ‚‚ avoided (kg)
  - Trees planted equivalent
  - Households powered (years)
  - km not driven
  - km not flown
  - Coal saved (kg)
  - Water saved (litres)

## âœ… Success Checklist

- [ ] Repository created and public
- [ ] GitHub Pages enabled
- [ ] 2 secrets added (SOLAR_EMAIL, SOLAR_PASSWORD)
- [ ] All files uploaded
- [ ] config.json updated with your values
- [ ] First workflow run successful (green checkmark)
- [ ] solar_data.json file created
- [ ] Dashboard loads at GitHub Pages URL
- [ ] Generation totals showing
- [ ] Environmental impact cards populated
- [ ] Yesterday's section showing data
- [ ] Day selector populated with past 7 days

## ğŸš€ Next Steps

1. Wait for sunset - workflow will run automatically
2. Check Actions tab next morning to verify it ran
3. View your dashboard at the GitHub Pages URL
4. Share the dashboard link with stakeholders!

## ğŸ“ Support

If you encounter issues:
1. Check Actions tab for error messages
2. Verify all secrets are set correctly
3. Ensure CSV downloads successfully
4. Check config.json values are correct

---

**Powered by Genergy** | Automated with GitHub Actions | Built with â¤ï¸
